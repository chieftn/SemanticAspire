{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.kusto.data import KustoConnectionStringBuilder\n",
    "from azure.kusto.data.helpers import dataframe_from_result_table\n",
    "from azure.kusto.data.aio import KustoClient\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import MarkdownConverter\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = \"https://icmclusterlb.kustomfa.windows.net\"\n",
    "kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(cluster)\n",
    "db = \"IcmDataWarehouse\"\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_record_set(client: KustoClient, current_top: datetime, current_floor: datetime):\n",
    "    query = f\"\"\"\n",
    "            Incidents\n",
    "        | where OwningTenantId  == 34793\n",
    "        | where IsNoise == false\n",
    "        | where CreateDate >= datetime({current_floor.year}-{current_floor.month}-{current_floor.day}) and CreateDate < datetime({current_top.year}-{current_top.month}-{current_top.day})\n",
    "        | sort by IncidentId desc\n",
    "        | project IncidentId, SourceType, CreateDate, RoutingId, OwningTeamName, OwningContactAlias, Severity, Status, Title, ReproSteps, Mitigation, RootCauseId, ImpactStartDate, HowFixed, Summary, ModifiedDate\n",
    "    \"\"\"\n",
    "    response = await client.execute(db, query)\n",
    "    return response\n",
    "\n",
    "async def get_records():\n",
    "    increment_weeks = 4\n",
    "    # floor = datetime(2025, 1, 1)\n",
    "    floor = datetime(2023, 1, 1)\n",
    "    current_floor = datetime.now()\n",
    "    current_top = current_floor + timedelta(weeks = increment_weeks)\n",
    "\n",
    "    async with KustoClient(kcsb) as client:\n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"getting incidents for {current_floor.strftime(\"%Y-%m-%d\")} through {current_top.strftime(\"%Y-%m-%d\")}\")\n",
    "                response = await get_record_set(client, current_top, current_floor)\n",
    "                results.append(response)  # Store KustoResponseDataSet\n",
    "\n",
    "                # Decrement\n",
    "                current_top = current_floor\n",
    "                current_floor = current_floor - timedelta(weeks = increment_weeks )\n",
    "\n",
    "                # Break the loop when reaching January 2023\n",
    "                if current_floor < floor:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                rest = 10\n",
    "                print(f\"sleeping for {rest} seconds\")\n",
    "                time.sleep(rest)\n",
    "\n",
    "await get_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    for nbsp in soup.find_all('nbsp'):\n",
    "        nbsp.replace_with(\" \")\n",
    "\n",
    "    # remove images for now\n",
    "    for img in soup.find_all('img'):\n",
    "        img.decompose()\n",
    "\n",
    "    return MarkdownConverter().convert_soup(soup)\n",
    "\n",
    "def format_records():\n",
    "    output_dir = \"../output/incidents\"\n",
    "    if (os.path.exists(output_dir)):\n",
    "        shutil.rmtree(output_dir)\n",
    "\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "    df_results = list(map(lambda result:  dataframe_from_result_table(result.primary_results[0]), results))\n",
    "    df_raw = pd.concat(df_results)\n",
    "    df_raw['Summary'] = df_raw['Summary'].apply(format_html)\n",
    "    df_raw['Mitigation'] = df_raw['Mitigation'].apply(format_html)\n",
    "    df_raw['HowFixed'] = df_raw['HowFixed'].apply(format_html)\n",
    "    df_raw['VectorText'] = '#Title\\n' + df_raw['Title'] + '\\n#Summary\\n' + df_raw['Summary']\n",
    "\n",
    "    df_sorted = df_raw.sort_values(by=\"ModifiedDate\", ascending=False)\n",
    "    df = df_sorted.drop_duplicates(subset=\"IncidentId\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = f\"{row['IncidentId']}.json\"\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        row_data = row.to_json(indent=4)\n",
    "\n",
    "        with open(file_path, \"w\", encoding='utf-8') as json_file:\n",
    "            json_file.write(row_data)\n",
    "\n",
    "format_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_files(folder_path):\n",
    "    json_entries = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                json_entries.append(data)\n",
    "\n",
    "    return json_entries\n",
    "\n",
    "# Compute similarity matrix using RapidFuzz\n",
    "def compute_similarity_matrix(entries):\n",
    "    size = len(entries)\n",
    "    similarity_matrix = np.zeros((size, size))\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(i, size):\n",
    "            if i == j:\n",
    "                similarity_matrix[i, j] = 100\n",
    "            else:\n",
    "                similarity_score = fuzz.ratio(entries[i].get('VectorText'), entries[j].get('VectorText'))\n",
    "                similarity_matrix[i, j] = similarity_score\n",
    "                similarity_matrix[j, i] = similarity_score\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "# Perform Agglomerative Clustering\n",
    "def cluster_entries(entries, threshold=50):\n",
    "    similarity_matrix = compute_similarity_matrix(entries)\n",
    "\n",
    "    # Convert similarity to distance (1 - similarity)\n",
    "    distance_matrix = 100 - similarity_matrix\n",
    "\n",
    "    clustering_model = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        metric=\"precomputed\",\n",
    "        linkage=\"average\",\n",
    "        distance_threshold=threshold\n",
    "    )\n",
    "\n",
    "    cluster_labels = clustering_model.fit_predict(distance_matrix)\n",
    "    return cluster_labels\n",
    "\n",
    "folder_path = \"../output/incidents\"  # Update this\n",
    "json_entries = load_json_files(folder_path)\n",
    "clusters = cluster_entries(json_entries)\n",
    "\n",
    "# Group JSON entries by cluster\n",
    "clustered_entries = {}\n",
    "for i, cluster in enumerate(clusters):\n",
    "    clustered_entries.setdefault(cluster, []).append(json_entries[i])\n",
    "\n",
    "# Convert to an array of arrays\n",
    "result = list(clustered_entries.values())\n",
    "\n",
    "output_dir = f\"../output/incidentClusters\"\n",
    "if (os.path.exists(output_dir)):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "for idx, cluster in enumerate(result):\n",
    "    file_name = f\"cluster_{idx + 1}.json\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    incident_ids = [item[\"IncidentId\"] for item in cluster]\n",
    "    for item in cluster:\n",
    "        item_incident_id = item[\"IncidentId\"]\n",
    "        incident_ids_copy = copy.deepcopy(incident_ids)\n",
    "        incident_ids_filter = [id for id in incident_ids_copy if id != item_incident_id]\n",
    "        item[\"SimilarIncidents\"] = incident_ids_filter\n",
    "\n",
    "    data = {\n",
    "        \"entries\": cluster\n",
    "    }\n",
    "    data_output = json.dumps(data, indent=4)\n",
    "\n",
    "    with open(file_path, \"w\", encoding='utf-8', errors=\"replace\") as cluster_file:\n",
    "        cluster_file.write(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_blob():\n",
    "    BLOB_URL = \"https://stvzac3zroquyd4.blob.core.windows.net/\"\n",
    "    CONTAINER_NAME = \"incidents\"\n",
    "    LOCAL_FOLDER = \"../output/incidentsClusters\"\n",
    "\n",
    "    credential = DefaultAzureCredential()\n",
    "    blob_service_client = BlobServiceClient(account_url=BLOB_URL, credential=credential)\n",
    "    container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
    "\n",
    "    # Ensure the container exists (create if necessary)\n",
    "    if not container_client.exists():\n",
    "        container_client.create_container()\n",
    "        print(f\"Created container: {CONTAINER_NAME}\")\n",
    "\n",
    "    # List all files in the local folder\n",
    "    for file_name in os.listdir(LOCAL_FOLDER):\n",
    "        file_path = os.path.join(LOCAL_FOLDER, file_name)\n",
    "\n",
    "        # Only upload files (skip directories)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Create a Blob Client for each file\n",
    "            blob_client = container_client.get_blob_client(file_name)\n",
    "\n",
    "            # Upload file to Azure Blob Storage\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "            print(f\"Uploaded: {file_name} -> {CONTAINER_NAME}/{file_name}\")\n",
    "\n",
    "upload_files_to_blob()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
